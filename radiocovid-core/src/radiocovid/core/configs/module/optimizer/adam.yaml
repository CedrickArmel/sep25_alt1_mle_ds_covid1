# @package module

defaults:
  - base_optimizer
  - _self_

optimizer:
  _target_: torch.optim.Adam
  betas:
    - 0.9
    - 0.999
  eps: 1e-8
  decoupled_weight_decay: true
  amsgrad: false
  capturable: false
