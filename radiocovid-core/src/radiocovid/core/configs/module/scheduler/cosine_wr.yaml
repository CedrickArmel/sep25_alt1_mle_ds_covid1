# @package module

# https://docs.pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  _partial_: true
  T_0: ??? # (int) – Number of iterations until the first restart.
  T_mult: ??? # (int, optional) – A factor by which Ti increases after a restart.
  eta_min: 0. # (float, optional) – Minimum learning rate.
  last_epoch: -1 # (int, optional) – The index of the last epoch.
