#@package _global_

defaults:
  - /module: default
  - /module/loss: focal_loss
  - /module/scheduler: sequential
  - /module/metric: fbeta_score
  - /module/optimizer: adamw
  - /datamodule
  - /trainer
  - /strategy: auto
  - /loggers: multiple
  - /callbacks: multiple

callbacks:
  model_checkpoint:
    dirpath: ${paths.output_dir}/checkpoints
    filename: e{epoch:03d}_s{step:06d}_{train_loss:.2e}_{val_loss:.2e}_{score:.2e}
    monitor: ${optimized_metric}
    mode: max
    save_last: True
    auto_insert_metric_name: False

  early_stopping:
    monitor: ${optimized_metric}
    patience: 100
    mode: max

  model_summary:
    max_depth: -1

datamodule:
  dataset:
    root: ???
    transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: torchvision.transforms.Grayscale
          num_output_channels: 3
        - _target_: torchvision.transforms.Resize
          size: 256
    loader:
      _partial_: true
      _target_: torchvision.datasets.folder.default_loader
    extensions: ["png"]
  train_transform:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.RandomApply
        transforms:
          - _target_: torchvision.transforms.RandomResizedCrop
            size: 256
            scale: [0.9, 1.1]
        p: 0.1
      - _target_: torchvision.transforms.RandomApply
        transforms:
          - _target_: torchvision.transforms.ColorJitter
            brightness: 0.1
            contrast: 0.2
        p: 0.1
      - _target_: torchvision.transforms.ToTensor
      - _target_: torchvision.transforms.Normalize
        mean: [120]
        std: [60]
  eval_transform:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.ToTensor
      - _target_: torchvision.transforms.Normalize
        mean: [120]
        std: [60]
  train_loader:
    num_workers: 10
    prefetch_factor: 64
  eval_loader:
    num_workers: 2
    prefetch_factor: 32
  test_size: 0.2
  val_size: 0.2
  class_retriever:
    _partial_: true
    _target_: radiocovid.core.data.get_label_from_sample

module:
  scheduler:
    schedulers:
      - _target_: torch.optim.lr_scheduler.LinearLR
        _partial_: true
        start_factor: 5e-1
        total_iters: 200
      - _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
        _partial_: true
        T_0: 64
        T_mult: 2
        eta_min: 5e-6
    milestones:
      - 200
  priors: [0.505, 0.495]

  optimizer:
    lr: 1e-5
    weight_decay: 0

  metric:
    num_classes: 2

trainer:
  gradient_clip_val: 10
  check_val_every_n_epoch: 100
  gradient_clip_algorithm: norm
  limit_val_batches: 0

optimized_metric: val_score

determinism:
  _target_: radiocovid.core.utils.set_seed
  seed: ${seed}
  cudnn_backend: false
  use_deterministic_algorithms: false
  warn_only: true

seed: 4294967295
tags:
  - dev
  - ${stage}
train: true
test: true
